# PyTorch Datasets & DataLoaders

이 프로젝트는 **PyTorch**에서 딥러닝 모델 학습을 위해 데이터를 처리하는 핵심적인 과정을 보여줍니다.  
`torch.utils.data.Dataset`과 `torch.utils.data.DataLoader` 두 가지 데이터 기본 요소(primitive)를 사용하여, 효율적이고 모듈화된 데이터 파이프라인을 구축하는 방법을 설명합니다.

---

## 주요 개념

프로젝트는 데이터 처리의 두 가지 핵심 구성 요소에 초점을 맞춥니다.

### Dataset
- 데이터 샘플과 그에 해당하는 레이블을 저장하는 추상 클래스입니다.  
- 개별 데이터 포인트를 가져오는 표준적인 방법을 제공합니다.

### DataLoader
- `Dataset`을 감싸는 이터레이터(iterable)로, 데이터를 **미니 배치(mini-batch)** 단위로 쉽게 접근할 수 있게 해줍니다.  
- 다음과 같은 기능을 제공합니다:
  - 데이터 **셔플링(Shuffling)**  
  - **배치화(Batching)**  
  - 멀티프로세싱을 통한 데이터 로딩 속도 향상  

---

## 프로젝트 구성

이 프로젝트는 두 가지 중요한 데이터 처리 방법을 예시로 보여줍니다.

### 1. 사전 로드된 데이터셋 로딩
- `torchvision.datasets.FashionMNIST`와 같은 내장 데이터셋을 사용하여 **학습 및 테스트 파이프라인**을 빠르게 구성합니다.  
- 주로 **모델 프로토타이핑**이나 **성능 벤치마킹**에 활용됩니다.

#### FashionMNIST 데이터셋
- 학습용: **60,000개 이미지**  
- 테스트용: **10,000개 이미지**  
- 각 이미지는 `28x28` 크기의 흑백 이미지  
- **10가지 클래스** 중 하나의 레이블을 가짐  

### 2. 커스텀 데이터셋 생성
직접 가지고 있는 이미지와 레이블을 사용하기 위해 `torch.utils.data.Dataset`을 상속받아 구현합니다.  
다음 세 가지 메소드를 반드시 구현해야 합니다.

- `__init__(...)` : 데이터셋 객체 생성 시 실행 (CSV 불러오기, 경로 초기화 등)  
- `__len__(...)` : 전체 샘플 수 반환  
- `__getitem__(idx)` : 주어진 인덱스에 해당하는 샘플(이미지 + 레이블) 반환 및 transform 적용  

---

## 데이터 처리 워크플로우

데이터는 아래 단계를 거쳐 모델 학습에 활용됩니다.

1. **Dataset 인스턴스화**  
   - 데이터를 `Dataset` 객체에 로드 → 개별 샘플 접근 가능  

2. **DataLoader에 전달**  
   - `Dataset`을 `DataLoader`에 전달 → 모델 학습에 적합한 형태로 변환  

   - **배치화 (Batching)**: 예) `batch_size=64`  
   - **셔플링 (Shuffling)**: 각 epoch마다 데이터 순서를 랜덤화  
   - **병렬 데이터 로딩**: `num_workers` 옵션 활용  

3. **반복 및 학습 (Training Loop)**  
   - `DataLoader`는 이터레이터 역할을 하여, 학습 루프에서 **미니 배치 단위**로 데이터를 쉽게 불러옴  

---

## 장점

이러한 **모듈화된 접근 방식** 덕분에:
- 데이터 처리 코드와 모델 학습 로직이 분리됨  
- 코드가 더 읽기 쉽고 유지보수하기 편리해짐  
- 대규모 데이터셋 처리 시 효율적인 파이프라인 구축 가능  

---
